apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  annotations:
    # This model is only available to premium and enterprise users
    alpha.maas.opendatahub.io/tiers: '["premium","enterprise"]'
  name: facebook-opt-125m-simulated-2
  namespace: llm
spec:
  model:
    name: facebook/opt-125m
    uri: hf://facebook/opt-125m
  replicas: 1
  router:
    gateway:
      refs:
      - name: maas-default-gateway
        namespace: openshift-ingress
    route: {}
  template:
    containers:
    - args:
      - --port
      - "8000"
      - --model
      - facebook/opt-125m
      - --mode
      - random
      - --ssl-certfile
      - /var/run/kserve/tls/tls.crt
      - --ssl-keyfile
      - /var/run/kserve/tls/tls.key
      command:
      - /app/llm-d-inference-sim
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: ghcr.io/llm-d/llm-d-inference-sim:v0.5.1
      imagePullPolicy: Always
      livenessProbe:
        httpGet:
          path: /health
          port: https
          scheme: HTTPS
      name: main
      ports:
      - containerPort: 8000
        name: https
        protocol: TCP
      readinessProbe:
        httpGet:
          path: /ready
          port: https
          scheme: HTTPS